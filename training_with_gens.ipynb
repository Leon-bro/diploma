{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T07:29:50.556761Z",
     "start_time": "2024-10-08T07:29:45.631037Z"
    }
   },
   "source": [
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from custom_losses import *\n",
    "from custom_metrics import *\n",
    "from preprocessing import *\n",
    "from models import create_unet, create_w_net, build_munet\n",
    "import patch_image\n",
    "import os\n",
    "import cv2\n",
    "from custom_callbacks import *\n",
    "from PIL import Image\n",
    "import dataset_generators\n",
    "from unet import create_unet1"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T07:29:50.603487Z",
     "start_time": "2024-10-08T07:29:50.556761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "# Set up the GPU memory growth option\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "e1dd1bec2115d648",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T07:29:50.619146Z",
     "start_time": "2024-10-08T07:29:50.603487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths to your dataset\n",
    "image_folder = 'DRIVE/training/images'\n",
    "label_folder = 'DRIVE/training/manual'\n",
    "mask_folder = 'DRIVE/training/mask'\n",
    "test_image_folder = 'DRIVE/test/images'\n",
    "test_label_folder = 'DRIVE/test/manual'\n",
    "test_mask_folder = 'DRIVE/training/mask'\n",
    "# Get list of all files in the image and label directories\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "label_files = sorted(os.listdir(label_folder))\n",
    "mask_files = sorted(os.listdir(mask_folder))\n",
    "test_image_files = sorted(os.listdir(test_image_folder))\n",
    "test_label_files = sorted(os.listdir(test_label_folder))\n",
    "test_mask_files = sorted(os.listdir(test_mask_folder))"
   ],
   "id": "5c25eb74c5e32c64",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T07:29:50.650796Z",
     "start_time": "2024-10-08T07:29:50.619146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_preproc = CLAHE()\n",
    "x = MedianBlurPreprocessor()(image_preproc)\n",
    "x = GammaCorrectionPreprocessor()(x)\n",
    "NormalizePreprocessor()(x)\n",
    "label_preproc = NormalizePreprocessor()\n",
    "# Function to load the dataset into tf.data.Dataset\n",
    "def create_dataset_with_amplification(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, data_size=1000, patch_size=48, batch_size=16):\n",
    "    # Create file paths\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    label_paths = [os.path.join(label_folder, f) for f in label_files]\n",
    "    mask_paths = [os.path.join(mask_folder, f) for f in mask_files]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: dataset_generators.generator_with_amplification(image_paths, label_paths, mask_paths, image_preproc, label_preproc, data_size, patch_size),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32),  # Image patch size\n",
    "            tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32)        # Label patch size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Shuffle, batch, and cache the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=data_size).batch(batch_size)  # Shuffle and batch the dataset\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "image_preproc2 = CLAHE()\n",
    "x = GammaCorrectionPreprocessor()(image_preproc)\n",
    "NormalizePreprocessor()(x)\n",
    "label_preproc2 = NormalizePreprocessor()\n",
    "def create_dataset_with_augmentation(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, data_size=1000, patch_size=48, batch_size=16):\n",
    "    # Create file paths\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    label_paths = [os.path.join(label_folder, f) for f in label_files]\n",
    "    mask_paths = [os.path.join(mask_folder, f) for f in mask_files]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: dataset_generators.generator_with_augmentation(image_paths, label_paths, mask_paths, image_preproc2, label_preproc2, data_size, patch_size),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32),  # Image patch size\n",
    "            tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32)        # Label patch size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Shuffle, batch, and cache the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=data_size).batch(batch_size)  # Shuffle and batch the dataset\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    return dataset\n",
    "image_preproc1 = ResizePreprocessor(512, 512)\n",
    "x = CLAHE()(image_preproc1)\n",
    "x = GammaCorrectionPreprocessor()(x)\n",
    "NormalizePreprocessor()(x)\n",
    "label_preproc1 = ResizePreprocessor(512, 512)\n",
    "x = NormalizePreprocessor()(label_preproc1)\n",
    "# Function to load the dataset into tf.data.Dataset\n",
    "def create_dataset(image_folder, image_files, label_folder, label_files, mask_folder, mask_files):\n",
    "    # Create file paths\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    label_paths = [os.path.join(label_folder, f) for f in label_files]\n",
    "    mask_paths = [os.path.join(mask_folder, f) for f in mask_files]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: dataset_generators.generator(image_paths, label_paths, mask_paths, image_preproc1, label_preproc1),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(512, 512, 1), dtype=tf.float32),  # Image patch size\n",
    "            tf.TensorSpec(shape=(512, 512, 1), dtype=tf.float32)        # Label patch size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Shuffle, batch, and cache the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_files)).batch(1)  # Shuffle and batch the dataset\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    return dataset\n"
   ],
   "id": "bd079f36cb765086",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T07:29:51.466099Z",
     "start_time": "2024-10-08T07:29:50.650796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset2 = create_dataset_with_augmentation(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, data_size=800, patch_size=256, batch_size=4)\n",
    "test_dataset2 = create_dataset_with_augmentation(test_image_folder, test_image_files,test_label_folder, test_label_files, test_mask_folder, test_mask_files, data_size=800, patch_size=256, batch_size=2)"
   ],
   "id": "c12618c7bd0a4cc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = create_dataset_with_amplification(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, data_size=800, patch_size=256, batch_size=4)\n",
    "test_dataset = create_dataset_with_amplification(test_image_folder, test_image_files,test_label_folder, test_label_files, test_mask_folder, test_mask_files, data_size=250, patch_size=256, batch_size=2)"
   ],
   "id": "601035df7691a5d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T09:27:08.452238Z",
     "start_time": "2024-10-06T09:20:56.457574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "munet = build_munet((256, 256, 1), first_filters=32, depth=4, keep_prob=.85, block_size=(7,5,5,3), reduction=8, L=16)  # Input is grayscale image\n",
    "\n",
    "munet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=CombainedDiceBinaryLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), dice_metric, tf.keras.metrics.binary_crossentropy])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)\n",
    "munet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"munet_res/training_res/munet_with_amplification{256}x{256}d{4}f{8}b{7}kp{0.85}.xlsx\"), LinearDecayScheduler()], validation_data=test_dataset)\n",
    "munet.save_weights(f\"munet_res/saved_model/munet_with_amplification_and_augmentation{256}x{256}d{4}f{8}b{((7,5,5,3))}kp{0.85}r4l8.h5\")"
   ],
   "id": "73d6fc958414f17e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.95e-07\n",
      "Epoch 1: Setting learning rate to 0.0000995050\n",
      "Epoch 1/800\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Learning rate is 9.950499952537939e-05\n",
      "200/200 - 46s - loss: 1.0266 - binary_io_u_3: 0.4413 - precision_3: 0.1117 - recall_3: 0.0020 - auc_3: 0.5124 - dice_metric: 0.3049 - binary_crossentropy: 0.4011 - val_loss: 1.0007 - val_binary_io_u_3: 0.4429 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.6786 - val_dice_metric: 0.3043 - val_binary_crossentropy: 0.3746 - epoch: 1.0000 - 46s/epoch - 231ms/step\n",
      "Epoch 2: Setting learning rate to 0.0000990100\n",
      "Epoch 2/800\n",
      "Epoch 2: Learning rate is 9.901000157697126e-05\n",
      "200/200 - 36s - loss: 1.0123 - binary_io_u_3: 0.4418 - precision_3: 0.1045 - recall_3: 1.9324e-05 - auc_3: 0.5442 - dice_metric: 0.3082 - binary_crossentropy: 0.3897 - val_loss: 1.1083 - val_binary_io_u_3: 0.4425 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.4583 - val_dice_metric: 0.1733 - val_binary_crossentropy: 0.3643 - epoch: 2.0000 - 36s/epoch - 182ms/step\n",
      "Epoch 3: Setting learning rate to 0.0000985150\n",
      "Epoch 3/800\n",
      "Epoch 3: Learning rate is 9.851500362856314e-05\n",
      "200/200 - 36s - loss: 1.0022 - binary_io_u_3: 0.4423 - precision_3: 0.1694 - recall_3: 2.1528e-04 - auc_3: 0.5726 - dice_metric: 0.3139 - binary_crossentropy: 0.3847 - val_loss: 1.0725 - val_binary_io_u_3: 0.4424 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.4742 - val_dice_metric: 0.2124 - val_binary_crossentropy: 0.3637 - epoch: 3.0000 - 36s/epoch - 180ms/step\n",
      "Epoch 4: Setting learning rate to 0.0000980200\n",
      "Epoch 4/800\n",
      "Epoch 4: Learning rate is 9.80199984041974e-05\n",
      "200/200 - 36s - loss: 0.9937 - binary_io_u_3: 0.4428 - precision_3: 0.2585 - recall_3: 0.0017 - auc_3: 0.5918 - dice_metric: 0.3209 - binary_crossentropy: 0.3825 - val_loss: 1.0611 - val_binary_io_u_3: 0.4450 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.4792 - val_dice_metric: 0.2162 - val_binary_crossentropy: 0.3557 - epoch: 4.0000 - 36s/epoch - 180ms/step\n",
      "Epoch 5: Setting learning rate to 0.0000975250\n",
      "Epoch 5/800\n",
      "Epoch 5: Learning rate is 9.752500045578927e-05\n",
      "200/200 - 36s - loss: 0.9861 - binary_io_u_3: 0.4427 - precision_3: 0.2183 - recall_3: 0.0035 - auc_3: 0.6089 - dice_metric: 0.3290 - binary_crossentropy: 0.3822 - val_loss: 1.1105 - val_binary_io_u_3: 0.4429 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.4593 - val_dice_metric: 0.1758 - val_binary_crossentropy: 0.3687 - epoch: 5.0000 - 36s/epoch - 180ms/step\n",
      "Epoch 6: Setting learning rate to 0.0000970300\n",
      "Epoch 6/800\n",
      "Epoch 6: Learning rate is 9.703000250738114e-05\n",
      "200/200 - 36s - loss: 0.9802 - binary_io_u_3: 0.4450 - precision_3: 0.2446 - recall_3: 0.0082 - auc_3: 0.6181 - dice_metric: 0.3314 - binary_crossentropy: 0.3785 - val_loss: 1.0874 - val_binary_io_u_3: 0.4440 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_auc_3: 0.4603 - val_dice_metric: 0.2084 - val_binary_crossentropy: 0.3749 - epoch: 6.0000 - 36s/epoch - 180ms/step\n",
      "Epoch 7: Setting learning rate to 0.0000965350\n",
      "Epoch 7/800\n",
      "Epoch 7: Learning rate is 9.65349972830154e-05\n",
      "200/200 - 36s - loss: 0.9775 - binary_io_u_3: 0.4467 - precision_3: 0.2949 - recall_3: 0.0131 - auc_3: 0.6229 - dice_metric: 0.3348 - binary_crossentropy: 0.3788 - val_loss: 1.1407 - val_binary_io_u_3: 0.4411 - val_precision_3: 0.0047 - val_recall_3: 2.0973e-04 - val_auc_3: 0.4246 - val_dice_metric: 0.1833 - val_binary_crossentropy: 0.4057 - epoch: 7.0000 - 36s/epoch - 181ms/step\n",
      "Epoch 8: Setting learning rate to 0.0000960400\n",
      "Epoch 8/800\n",
      "Epoch 8: Learning rate is 9.603999933460727e-05\n",
      "200/200 - 36s - loss: 0.9741 - binary_io_u_3: 0.4465 - precision_3: 0.2546 - recall_3: 0.0148 - auc_3: 0.6299 - dice_metric: 0.3391 - binary_crossentropy: 0.3793 - val_loss: 1.1023 - val_binary_io_u_3: 0.4424 - val_precision_3: 0.0505 - val_recall_3: 4.8293e-04 - val_auc_3: 0.4425 - val_dice_metric: 0.2083 - val_binary_crossentropy: 0.3898 - epoch: 8.0000 - 36s/epoch - 181ms/step\n",
      "Epoch 9: Setting learning rate to 0.0000955450\n",
      "Epoch 9/800\n",
      "Epoch 9: Learning rate is 9.554500138619915e-05\n",
      "200/200 - 37s - loss: 0.9707 - binary_io_u_3: 0.4487 - precision_3: 0.2738 - recall_3: 0.0193 - auc_3: 0.6338 - dice_metric: 0.3401 - binary_crossentropy: 0.3768 - val_loss: 1.0939 - val_binary_io_u_3: 0.4441 - val_precision_3: 0.0455 - val_recall_3: 3.9390e-04 - val_auc_3: 0.4630 - val_dice_metric: 0.2066 - val_binary_crossentropy: 0.3798 - epoch: 9.0000 - 37s/epoch - 184ms/step\n",
      "Epoch 10: Setting learning rate to 0.0000950500\n",
      "Epoch 10/800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m wrapper\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1E-4\u001B[39m), loss\u001B[38;5;241m=\u001B[39mCombainedDiceBinaryLoss(), metrics\u001B[38;5;241m=\u001B[39m[tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mBinaryIoU(), tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mPrecision(), tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mRecall(), tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mAUC(), dice_metric, tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mbinary_crossentropy])\n\u001B[0;32m      5\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mwrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m800\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLearningRateLogger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLogHistoryToExcel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmunet_res/training_res/munet_with_amplification\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m256\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m256\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43md\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m4\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m8\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m7\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mkp\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;241;43m0.85\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.xlsx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLinearDecayScheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m wrapper\u001B[38;5;241m.\u001B[39msave_weights(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmunet_res/saved_model/munet_with_amplification_and_augmentation\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m256\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mx\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m256\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124md\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m4\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mf\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m8\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mb\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m((\u001B[38;5;241m7\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m3\u001B[39m))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mkp\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m0.85\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mr4l8.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1606\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1593\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1594\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1604\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[0;32m   1605\u001B[0m     )\n\u001B[1;32m-> 1606\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1607\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1608\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1609\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1610\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1611\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1617\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1619\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1620\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1621\u001B[0m }\n\u001B[0;32m   1622\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1947\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1944\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1945\u001B[0m ):\n\u001B[0;32m   1946\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1947\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1949\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5f9b342a57666b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd75e805cd853c4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#dataset = create_dataset(image_folder, image_files, label_folder, label_files, mask_folder, mask_files)\n",
    "#test_dataset = create_dataset(test_image_folder, test_image_files,test_label_folder, test_label_files, test_mask_folder, test_mask_files)"
   ],
   "id": "90668456acdcbc2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image, label in test_dataset:\n",
    "    for i, l in zip(image, label):\n",
    "        print(tf.reduce_max(i), tf.reduce_max(l))\n",
    "        pass\n",
    "        #fig, axs = plt.subplots(1, 2)\n",
    "        #axs[0].imshow(i, cmap=\"gray\")\n",
    "        #axs[1].imshow(l, cmap=\"gray\")\n",
    "        #plt.show()"
   ],
   "id": "bb96381cf7ddf09a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Set the initial learning rate, decay steps, and minimum learning rate\n",
    "initial_learning_rate = 1E-3\n",
    "decay_steps = 200\n",
    "alpha = 1E-6\n",
    "\n",
    "# Create a cosine decay schedule with restarts and a minimum learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    alpha=alpha\n",
    ")"
   ],
   "id": "20cf7ecb88be904c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e3e0ebf776693d62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wnet = build_munet((256, 256, 1), first_filters=8, depth=4, keep_prob=.85, block_size=(7,5,5,3), reduction=4, L=4)  # Input is grayscale image\n",
    "wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=CombainedDiceBinaryLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), dice_metric, tf.keras.metrics.binary_crossentropy])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)\n",
    "wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"munet_res/training_res/munet_with_amplification{256}x{256}d{4}f{8}b{7}kp{0.85}.xlsx\"), LinearDecayScheduler()], validation_data=test_dataset)\n",
    "wnet.save_weights(f\"munet_res/saved_model/munet_with_amplification{256}x{256}d{4}f{8}b{7}kp{0.85}.h5\")"
   ],
   "id": "e84053e725c362a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = [[8, 4, .85, (7,5,5,3), 4, 8], \n",
    "          [16, 3, .7, (7,5,5,3), 4, 8],\n",
    "          [8, 2, .85, (7,5,5,3), 4, 8], \n",
    "          [16, 2, .7, (7,5,5,3), 4, 8], \n",
    "          [32, 3, .5, (7,5,5,3), 8, 16], \n",
    "          [16, 4, .9, (7,5,5,3), 8, 8], \n",
    "          [32, 2, .85, (7,5,5,3), 8, 8], \n",
    "          [4, 4, .9, (7,5,5,3), 4, 8], ]\n",
    "for i in params:\n",
    "    wnet = build_munet((256, 256, 1), *i)  # Input is grayscale image\n",
    "    wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=CombainedDiceBinaryLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), dice_metric, tf.keras.metrics.binary_crossentropy])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)\n",
    "    wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"munet_res/training_res/munet_with_amplification{256}x{256}d{i[1]}f{i[0]}b{i[3]}kp{i[2]}red{i[4]}L{i[5]}.xlsx\"), LinearDecayScheduler()], validation_data=test_dataset)\n",
    "    wnet.save_weights(f\"munet_res/saved_model/munet_with_amplification{256}x{256}d{i[1]}f{i[0]}b{i[3]}kp{i[2]}red{i[4]}L{i[5]}.h5\")"
   ],
   "id": "7749df243e99aaca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for d in range(3,5):\n",
    "    for fil in range(16, 36, 16):\n",
    "        for keep_prob in (0.7, 0.9):\n",
    "            for block_size in (3, 5):\n",
    "                print(\"depth:\", d, \"filters:\", fil, \"block_size:\", block_size, \"keep_prob:\", keep_prob)\n",
    "                wnet = build_munet((256, 256, 1), fil, d, keep_prob, block_size)  # Input size is 128x128 grayscale image\n",
    "                wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=CombainedDiceBinaryLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])\n",
    "                early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)\n",
    "                wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"munet_res/training_res/munet_with_amplification{256}x{256}d{d}f{fil}b{block_size}kp{keep_prob}.xlsx\"), LinearDecayScheduler()], validation_data=test_dataset)\n",
    "                wnet.save_weights(f\"munet_res/saved_model/munet_with_amplification{256}x{256}d{d}f{fil}b{block_size}kp{keep_prob}.h5\")"
   ],
   "id": "11ba7debf9248ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "15e469bcceb6c672",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b66cc8735d848a8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "235077cc6f1b0dbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e0fb0d404c4bd8db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c45b5aa6ec84027e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unet = create_unet((512,512,1), 4, 64)\n",
    "unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=DiceLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
    "unet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(\"bared_unet.xlsx\")], validation_data=test_dataset)"
   ],
   "id": "49e6c69efc01ab0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unet = create_unet1((512,512,1), 4, 64)\n",
    "unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-4), loss=CombainedDiceBinaryLoss(), metrics=[tf.keras.metrics.BinaryIoU(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min')\n",
    "unet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(\"unet_with_multiscale_module_keep_prob_0_15.xlsx\")], validation_data=test_dataset)"
   ],
   "id": "43da27b680734d9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for d in range(2,5):\n",
    "    for fil in range(4, 24, 4):\n",
    "        print(\"depth:\", d, \"filters:\", fil)\n",
    "        wnet = create_w_net((128, 128, 1), d, fil)  # Input size is 128x128 grayscale image\n",
    "        wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-3), loss=DiceLoss(), metrics=[tf.keras.metrics.BinaryIoU()])\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
    "        wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"model_with_amplification128x128, {d}, {fil}.xlsx\")], validation_data=test_dataset)\n",
    "        wnet.save_weights(f\"model_with_amplification{128}x{128}d{d}f{fil}.h5\")"
   ],
   "id": "c281d7f1b391f0eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = create_dataset(image_folder, image_files, label_folder, label_files, mask_folder, mask_files)\n",
    "test_dataset = create_dataset(test_image_folder, test_image_files,test_label_folder, test_label_files, test_mask_folder, test_mask_files)"
   ],
   "id": "377f07b97592b18a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ffaeb865b08f0262",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e5538726a71b3d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for din in range(3, 6):\n",
    "    for fil in range(16, 128, 16):\n",
    "        print(\"depth:\", d, \"filters:\", fil)\n",
    "        wnet = create_w_net((512, 512, 1), d, fil)  # Input size is 128x128 grayscale image\n",
    "        wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-3), loss=DiceLoss(), metrics=[tf.keras.metrics.BinaryIoU()])\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, verbose=1, mode='min')\n",
    "        wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"model_with_preproc512x512, {d}, {fil}.xlsx\")], validation_data=test_dataset)\n",
    "        wnet.save_weights(f\"model_with_preproc{512}x{512}d{d}f{fil}.h5\")"
   ],
   "id": "47b74cdbc41404ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wnet = create_w_net((48, 48, 1), 2, 4)  # Input size is 128x128 grayscale image\n",
    "wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-3), loss={\"out1\":DiceLoss(), \"out2\":DiceLoss()}, metrics=[tf.keras.metrics.BinaryIoU()])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, verbose=1, mode='min')\n",
    "wnet.fit(x=dataset, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger(), LogHistoryToExcel(f\"model_with_amplification48x48, {2}, {4}.xlsx\")], validation_data=test_dataset)\n",
    "wnet.load_weights(f\"model_with_amplification{48}x{48}d{2}f{4}.h5\")"
   ],
   "id": "c9b2fc48cfb53a2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c5f926d26c71ee21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wnet.load_weights(\"model_with_amplification64x64.h5\")",
   "id": "ecc0746d72cf510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_image_paths = [os.path.join(test_image_folder, f) for f in test_image_files]\n",
    "test_label_paths = [os.path.join(test_label_folder, f) for f in test_label_files]\n",
    "for i, l in zip(test_image_paths, test_label_paths):\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    label = Image.open(l)\n",
    "    label = np.array(label)\n",
    "    img = image_preproc.process(img)[:, :, np.newaxis].astype(np.float32)\n",
    "    lb = label_preproc.process(label)[:, :, np.newaxis].astype(np.float32)\n",
    "    print(img.shape)\n",
    "    patches, size = patch_image.split_image_into_patches(img, 64)\n",
    "    patches = np.asarray(patches)\n",
    "    print(patches.shape)\n",
    "    pl = wnet.predict(patches)[1]\n",
    "    print(pl.dtype)\n",
    "    #for k in pl:\n",
    "        #plt.imshow(k, cmap=\"gray\")\n",
    "        #plt.show()\n",
    "    predicted_label = patch_image.merge_patches_into_image(pl, size, 64)\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    axs[0].imshow(predicted_label, cmap='gray')\n",
    "    axs[1].imshow(label, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ],
   "id": "7df891d96ceeef5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image, label in dataset:\n",
    "    pl = wnet.predict(image)[1]\n",
    "    print(DiceLoss()(label, pl))\n",
    "    for i, p, l in zip(image, pl, label):\n",
    "        fig, axs = plt.subplots(1, 3)\n",
    "        axs[0].imshow(i, cmap=\"gray\")\n",
    "        axs[1].imshow(p, cmap=\"gray\")\n",
    "        axs[2].imshow(l, cmap=\"gray\")\n",
    "        plt.show()\n",
    "    break"
   ],
   "id": "df1f3bfca0148c49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "de01a10a225447fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "height, width, dims = 512, 512, 3\n",
    "image_preproc = ResizePreprocessor(height=height, width=width)\n",
    "x = CLAHE()(image_preproc)\n",
    "x = MedianBlurPreprocessor()(x)\n",
    "x = GammaCorrectionPreprocessor()(x)\n",
    "x = MultiScaleMorphologicalPreprocessor(\n",
    "    operation='open',  # Options: 'dilate', 'erode', 'open', 'close'\n",
    "    kernel_sizes=[3, 5, 7],\n",
    "    kernel_shape=cv2.MORPH_RECT,\n",
    "    iterations=1\n",
    ")(x)\n",
    "NormalizePreprocessor()(image_preproc)\n",
    "label_preproc = NormalizePreprocessor()\n",
    "# Function to load the dataset into tf.data.Dataset\n",
    "def create_dataset(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, height=512, width=512, dims=1):\n",
    "    # Create file paths\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    label_paths = [os.path.join(label_folder, f) for f in label_files]\n",
    "    mask_paths = [os.path.join(mask_folder, f) for f in mask_files]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: dataset_generators.generator(image_paths, label_paths, mask_paths, image_preproc, label_preproc),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(height, width, dims), dtype=tf.float32),  # Image patch size\n",
    "            tf.TensorSpec(shape=(height, width, 1), dtype=tf.float32)        # Label patch size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Shuffle, batch, and cache the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths)).batch(4)  # Shuffle and batch the dataset\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    return dataset\n"
   ],
   "id": "dcebf53e5ee54727",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ds = create_dataset(image_folder, image_files, label_folder, label_files, mask_folder, mask_files, height, width, dims)",
   "id": "34ae93d8c1a03ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "86e982131cd54d75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1E-3), loss={\"out1\":DiceLoss(), \"out2\":DiceLoss()}, metrics=[tf.keras.metrics.BinaryIoU()])",
   "id": "239292ee104e59d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50, verbose=1, mode='min')\n",
    "wnet.fit(x=ds, epochs=800, verbose=2, callbacks=[early_stopping, LearningRateLogger()])"
   ],
   "id": "2cee1f8e820bdbc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "811cd0eebfc3e313",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
