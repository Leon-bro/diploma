{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T06:46:26.765817Z",
     "start_time": "2024-09-06T06:46:26.759175Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:46:27.015079Z",
     "start_time": "2024-09-06T06:46:26.997690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths to your dataset\n",
    "image_folder = 'DRIVE/training/images'\n",
    "label_folder = 'DRIVE/training/1st_manual'\n",
    "\n",
    "# Get list of all files in the image and label directories\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "label_files = sorted(os.listdir(label_folder))\n",
    "\n"
   ],
   "id": "16b9fee2f4e7037f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:52:20.619961Z",
     "start_time": "2024-09-06T06:52:20.609951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to preprocess images and labels\n",
    "def preprocess(image_path, label_path):\n",
    "    # Convert the TensorFlow Tensor object to a string\n",
    "    image_path = image_path.decode('utf-8')\n",
    "    label_path = label_path.decode('utf-8')\n",
    "    # Load image and label\n",
    "    image = cv2.imread(image_path)\n",
    "    label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize images and labels\n",
    "    image_resized = cv2.resize(image, (512, 512))\n",
    "    label_resized = cv2.resize(label, (512, 512))\n",
    "    \n",
    "    # Normalize images and labels\n",
    "    image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "    label_normalized = label_resized.astype(np.float32) / 255.0\n",
    "    \n",
    "    return image_normalized, label_normalized\n",
    "\n"
   ],
   "id": "a404fe4f32da8c39",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:54:06.193003Z",
     "start_time": "2024-09-06T06:54:06.183002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to load the dataset into tf.data.Dataset\n",
    "def load_dataset(image_folder, label_folder):\n",
    "    # Create file paths\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "    label_paths = [os.path.join(label_folder, f) for f in label_files]\n",
    "    # Create a TensorFlow dataset from the file paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, label_paths))\n",
    "    \n",
    "    # Map the preprocessing function to each element in the dataset\n",
    "    dataset = dataset.map(lambda img_path, lbl_path: tf.numpy_function(\n",
    "                          func=preprocess, inp=[img_path, lbl_path], \n",
    "                          Tout=[tf.float32, tf.float32]))\n",
    "    \n",
    "    # Shuffle and batch the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    dataset = dataset.batch(4)  # Set batch size to 32, modify as needed\n",
    "    \n",
    "    return dataset\n",
    "\n"
   ],
   "id": "30c38d083ec2e55",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:54:06.577994Z",
     "start_time": "2024-09-06T06:54:06.562684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(image_folder, label_folder)"
   ],
   "id": "ffaae233c084e2f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:54:07.490282Z",
     "start_time": "2024-09-06T06:54:07.226221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: iterate over the dataset\n",
    "for batch in dataset:\n",
    "    images, labels = batch\n",
    "    print(f'Batch of images shape: {images.shape}')\n",
    "    print(f'Batch of labels shape: {labels.shape}')"
   ],
   "id": "c6902d972cb43186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images shape: (4, 512, 512, 3)\n",
      "Batch of labels shape: (4, 512, 512)\n",
      "Batch of images shape: (4, 512, 512, 3)\n",
      "Batch of labels shape: (4, 512, 512)\n",
      "Batch of images shape: (4, 512, 512, 3)\n",
      "Batch of labels shape: (4, 512, 512)\n",
      "Batch of images shape: (4, 512, 512, 3)\n",
      "Batch of labels shape: (4, 512, 512)\n",
      "Batch of images shape: (4, 512, 512, 3)\n",
      "Batch of labels shape: (4, 512, 512)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11d15fcc329b833c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
